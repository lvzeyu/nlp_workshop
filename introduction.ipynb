{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# イントロダクション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 背景\n",
    "\n",
    "### はじめに\n",
    "\n",
    "自然言語処理（NLP: Natural Language Processing）は、人間が日常的に使っている自然言語をコンピュータに処理させる一連の技術であり、人工知能（AI）の研究分野で中核を成す要素技術の一つといえます。\n",
    "\n",
    "私たちは普段、自分たちの言語の複雑さについて考えることはありません。言語は歩くのと同じように、訓練された反復可能な行動であるため、習得しやすく、青年期にはより自然に使用できるようになると言われています。ただ、人間にとって自然なことでも、大量の非構造化データを処理し、正式なルールがないばかりか、現実世界のコンテキストや意図もないコンピューターにとっては、それを成すことは非常に困難です。\n",
    "\n",
    "近年、自然言語処理技術の急速な進歩に驚きの声が上がっていました。\n",
    "\n",
    "実際、自然言語処理において昨今の支配的な手法は、隠れマルコフモデル(HMM)、線型サポートベクトルマシン(SVM)やロジスティック回帰など統計的機械学習(statistical machine learning)に基づいていました。\n",
    "\n",
    "2014年頃、この分野において、非線型ニューラルネットワークが導入され、多くのタスクにより高い性能を達成できました。これに基づいて、より先進的なモデリング方法の開発も進めました。特に、再帰的ニューラルネットワーク(RNN)に基づく方法は言語の時系列性質も学習できるになって、様々なタスクにおいて精度向上に大きく貢献しました。\n",
    "\n",
    "2018年にGoogleが発表した「BERT」というシステムでは、開発者が少し手を加えるだけでさまざまなタスクに使えるようになりました。それだけでも驚きでしたが、一般人の中でも話題になる「ChatGPT」をはじめとする自然言語処理技術の進展により、質問への回答、文章の要約や翻訳、ソフトウエアのプログラミングなど、言語に関わるさまざまなタスクができるようになりました。\n",
    "\n",
    "高機能化のカギは、深層学習技術の発展があります。深層学習を用いた自然言語処理には、あらかじめ用意した膨大な文章を使って、「言語モデル」と呼ばれるシステムを学習させる方法があります。\n",
    "言語モデルの実体は簡単な計算式を大量に組み合わせた超巨大な数式といえます。最先端の言語モデルでは、想像を絶するほど大量の文章を使い、パラメータ（数式の係数）が数千億に達するほどの大規模な言語モデル(LLM : Large Language Models)を学習させて使っています。LLMが人間に匹敵するほどの高度な能力を持つ、文章の作成や会話を利用するさまざまな仕事を、コンピュータに任せることが可能になってきました。\n",
    "\n",
    "### テキスト分類\n",
    "\n",
    "テキスト分類とは、事前定義済みカテゴリまたはラベルを非構造化テキスト形式に割り当てる処理のことです。主な使用例として、感情分析、偽情報の検出や内容判定などが挙げられます。\n",
    "\n",
    "言語は本質的に曖昧で、変化し続け、適切に定義されていないため、テキスト分類は決して簡単なタスクではないが、深層学習による自然言語処理が発展したことにより、高精度化させることが可能になってきています。\n",
    "\n",
    "とくに2018年に発表されたBERT {cite}`Devlin2019` はセンチメント分析を含めた多くのタスクに関して、当時の最高性能(SOTA: State of the Art)を達成する画期的な技術でした。\n",
    "\n",
    "BERTは事前学習モデルの一種で、事前に一定のタスクに基づいて事前学習することで汎用性を獲得することに特徴があります。そのため、特定のタスクについてより少ないデータで性能を発揮することができます。 \n",
    "\n",
    "BERTのような事前学習モデルによるテキスト分類の社会科学における応用可能性について多くの注目を集めています {cite}`laurer_van`。\n",
    "\n",
    "![](./Figure/text_class.png)\n",
    "\n",
    "### 今回のワークショップで扱うこと\n",
    "\n",
    "参加者は形態素解析やテキストデータの前処理など自然言語処理の基礎知識を持つ方を想定していますので、今回のワークショップは以下の内容を扱います：\n",
    "- 転移学習とファインチューニングによるテキスト分類の枠組\n",
    "- Hugging Face PyTorchインタフェース\n",
    "- Transformersによるセンチメント分析の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
